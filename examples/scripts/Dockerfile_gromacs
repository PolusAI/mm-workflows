FROM nvidia/cuda:11.8.0-devel-ubuntu22.04 as devel

# SHELL ["/bin/bash", "-c"]

# NOTE: The version of cudatoolkit-dev on conda-forge is still 11.7,
# but gromacs 2023 requires 11.8. When that changes, we can do
# mamba install -c conda-forge cmake cudatoolkit-dev

ARG GMX_VERSION=2023.2
# Prevent being prompted for geographical region
ARG DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y wget cmake

# Compile gromacs
# See https://manual.gromacs.org/2023.2/install-guide/index.html
RUN wget https://ftp.gromacs.org/gromacs/gromacs-${GMX_VERSION}.tar.gz
RUN tar xfz gromacs-${GMX_VERSION}.tar.gz
RUN cd gromacs-${GMX_VERSION}/ && mkdir build
# NOTE: The official gromacs/gromacs docker images change the default
# install prefix from /usr/local/gromacs to /gromacs
RUN cd gromacs-${GMX_VERSION}/build && cmake .. -DGMX_BUILD_OWN_FFTW=ON -DGMX_GPU=CUDA -DGMX_SIMD=AVX2_256 -DCMAKE_INSTALL_PREFIX=/gromacs
# https://stackoverflow.com/questions/73719229/gcc-compilation-within-docker-with-j
# gromacs' Makefiles appear to have race conditions. So compile in parallel
# several times so we don't end up compiling with 1 process in make install
# This reduces compilation time from 15-20 mins to 7-8 mins.
# Do it all in one RUN command so we get deterministic image layers.
RUN cd gromacs-${GMX_VERSION}/build && make -j16 && make -j16 && make -j16 && make -j16 && make -j16

# Install gromacs (again, to /gromacs)
RUN cd gromacs-${GMX_VERSION}/build && make install
# TODO: Figure out how to source GMXRC so we can use "gmx" instead of "/gromacs/bin/gmx"

ADD Dockerfile_gromacs .

# Now copy everything into a minimal cuda runtime base image.
# (~2GB instead of ~7GB)
FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04 as runtime

# Install openmp
RUN apt-get update && apt-get install -y libgomp1

COPY --from=devel gromacs/ gromacs/
COPY --from=devel Dockerfile_gromacs ./